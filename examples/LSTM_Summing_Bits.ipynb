{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lstm import LSTMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pizza as pz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-bits summation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training dataset generation\n",
    "int2binary = {}\n",
    "binary_dim = 8\n",
    "\n",
    "largest_number = pow(2, binary_dim)  # 256\n",
    "binary = np.unpackbits(np.array([range(largest_number)], dtype=np.uint8).T,axis=1) # 256, 8\n",
    "for i in range(largest_number):\n",
    "    int2binary[i] = binary[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_to_int = lambda t: sum([_t * pow(2, i) for i, _t in enumerate(reversed(t))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetcher():\n",
    "    # generate a simple addition problem (a + b = c)\n",
    "    a_int = np.random.randint(largest_number/2) # int version\n",
    "    a = list(reversed(int2binary[a_int])) # binary encoding\n",
    "    b_int = np.random.randint(largest_number/2) # int version\n",
    "    b = list(reversed(int2binary[b_int])) # binary encoding\n",
    "    # true answer\n",
    "    c_int = a_int + b_int\n",
    "    c = list(reversed(int2binary[c_int]))\n",
    "    return T.tensor(np.stack((a, b)), dtype=T.float64), T.tensor(np.reshape(c, (1, -1)), dtype=T.float64)\n",
    "\n",
    "\n",
    "def hook(model, loss, y_preds, j, X, y):\n",
    "    print_every = 1000\n",
    "    if j % print_every == 0:\n",
    "        a = list(reversed([int(_x) for _x in X[0]]))\n",
    "        b = list(reversed([int(_x) for _x in X[1]]))\n",
    "        c = list(reversed([int(_y) for _y in y.squeeze()]))\n",
    "        \n",
    "        print()\n",
    "        print('[{0}] Loss batch : {1:.4f}'.format(j, loss))\n",
    "        print('      {0}'.format(a))\n",
    "        print('  +   {0}'.format(b))\n",
    "        print('-' * 35)\n",
    "        print('      {0}'.format(c))\n",
    "        d = [int(np.round(p[0, 0])) for p in reversed(y_preds)]\n",
    "        print('Pred: {0}'.format(d))\n",
    "        print('{0} + {1} = {2}'.format(binary_to_int(a), binary_to_int(b), binary_to_int(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0] Loss batch : 0.2531\n",
      "      [0, 0, 0, 0, 1, 0, 1, 0]\n",
      "  +   [0, 1, 1, 0, 1, 0, 1, 0]\n",
      "-----------------------------------\n",
      "      [0, 1, 1, 1, 0, 1, 0, 0]\n",
      "Pred: [1, 1, 1, 1, 1, 0, 1, 0]\n",
      "10 + 106 = 250\n",
      "\n",
      "[1000] Loss batch : 0.0123\n",
      "      [0, 0, 1, 0, 1, 1, 1, 1]\n",
      "  +   [0, 1, 1, 1, 0, 0, 1, 0]\n",
      "-----------------------------------\n",
      "      [1, 0, 1, 0, 0, 0, 0, 1]\n",
      "Pred: [1, 0, 1, 0, 0, 0, 0, 1]\n",
      "47 + 114 = 161\n",
      "\n",
      "[2000] Loss batch : 0.0052\n",
      "      [0, 1, 1, 0, 0, 1, 0, 1]\n",
      "  +   [0, 0, 0, 1, 1, 0, 1, 1]\n",
      "-----------------------------------\n",
      "      [1, 0, 0, 0, 0, 0, 0, 0]\n",
      "Pred: [1, 0, 0, 0, 0, 0, 0, 0]\n",
      "101 + 27 = 128\n",
      "\n",
      "[3000] Loss batch : 0.0020\n",
      "      [0, 1, 1, 0, 1, 0, 1, 1]\n",
      "  +   [0, 1, 0, 0, 0, 1, 0, 1]\n",
      "-----------------------------------\n",
      "      [1, 0, 1, 1, 0, 0, 0, 0]\n",
      "Pred: [1, 0, 1, 1, 0, 0, 0, 0]\n",
      "107 + 69 = 176\n",
      "\n",
      "[4000] Loss batch : 0.0001\n",
      "      [0, 0, 1, 0, 1, 0, 0, 0]\n",
      "  +   [0, 1, 0, 0, 0, 0, 1, 0]\n",
      "-----------------------------------\n",
      "      [0, 1, 1, 0, 1, 0, 1, 0]\n",
      "Pred: [0, 1, 1, 0, 1, 0, 1, 0]\n",
      "40 + 66 = 106\n",
      "\n",
      "[5000] Loss batch : 0.0001\n",
      "      [0, 1, 1, 0, 1, 0, 1, 1]\n",
      "  +   [0, 0, 0, 1, 0, 0, 0, 0]\n",
      "-----------------------------------\n",
      "      [0, 1, 1, 1, 1, 0, 1, 1]\n",
      "Pred: [0, 1, 1, 1, 1, 0, 1, 1]\n",
      "107 + 16 = 123\n"
     ]
    }
   ],
   "source": [
    "least_square = lambda a, b: (a - b).pow(2.)[0, 0]\n",
    "# pytorch has a tough time trying to optimize absolute loss\n",
    "absolute_loss = lambda a, b: T.abs(a - b)[0, 0]\n",
    "\n",
    "params_lstm = {'n_in': 2, 'n_hidden1': 12, 'n_hidden2': 6, 'n_out': 1, \n",
    "               'optimizer': pz.Adagrad(), 'learning_rate': -0.1, 'clamping': 20., \n",
    "               'compute_loss': least_square, 'out_nonlinear': T.sigmoid, 'device': T.device('cpu'),\n",
    "               'w_init': (None, None)\n",
    "              }\n",
    "\n",
    "lstm_model = LSTMModel(params_lstm)\n",
    "lstm_model.train(n_iterations=5000, fetcher=fetcher, hook=hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numbers(a_int, b_int, length=8):\n",
    "    # generate a simple addition problem (a + b = c)\n",
    "    a = list(reversed(int_to_binary(a_int, length))) # binary encoding\n",
    "    b = list(reversed(int_to_binary(b_int, length))) # binary encoding\n",
    "    # true answer\n",
    "    c_int = a_int + b_int\n",
    "    c = list(reversed(int_to_binary(c_int, length)))\n",
    "    return T.tensor(np.stack((a, b)), dtype=T.float64), T.tensor(np.reshape(c, (1, -1)), dtype=T.float64)\n",
    "\n",
    "\n",
    "def test_random_sum(max_number, min_number=None, n_test=100, model=None, length=8):\n",
    "    min_number = 0 if min_number is None else min_number\n",
    "    print('Testing random sum for numbers < {0} and > {1}, with sum smaller than {2}'.format(max_number, \n",
    "                                                                                             min_number, 2**length))\n",
    "    n_fail = 0\n",
    "    for i in range(n_test):\n",
    "        a = np.random.randint(low=min_number, high=max_number)\n",
    "        b = np.random.randint(low=min_number, high=max_number)\n",
    "        c = a + b\n",
    "        _a, _b = get_numbers(a, b, length)\n",
    "        \n",
    "        loss, y_preds = model.forward(_a, _b, train=False)\n",
    "        d = binary_to_int([int(np.round(p)) for p in reversed(y_preds)])\n",
    "        if c != d:\n",
    "            n_fail += 1\n",
    "            print('Fail at {0} + {1} = {2}'.format(a, b, d))\n",
    "    print('total failures: {0}'.format(n_fail))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
